---
title: "Homework 6"
author: "Wenhao Gou"
date: "2020/12/8"
output: github_document
---

```{r setup, include=FALSE}
library(tidyverse)
library(modelr)
knitr::opts_chunk$set(message = F,
                      warning = F)
set.seed(1)
```

## Question 1:


### Clean and tidy the dataset:
Firstly, create and clean the dataset we need to use in further analysis:

```{r, tidy the dataset}
homicide_clean = 
  read_csv("data/homicide-data.csv", na = c("", "NA", "Unknown")) %>% 
  mutate(
    city_state = str_c(city, state, sep = ", "),
    victim_age = as.numeric(victim_age),
    resolution = case_when(
      disposition == "Closed without arrest" ~ 0,
      disposition == "Open/No arrest"        ~ 0,
      disposition == "Closed by arrest"      ~ 1)
  ) %>% 
  filter(
    victim_race %in% c("White", "Black"),
    city_state != "Tulsa, AL",
    city_state != "Dallas, TX",
    city_state != "Phoenix, AZ",
    city_state != "Kansas City, MO") %>% 
  select(city_state, resolution, victim_age, victim_race, victim_sex)
```

### Logsictic regression on Baltimore, MD

```{r model for Baltimore MD}

model_Baltimore <-
  homicide_clean %>% 
  filter(city_state == "Baltimore, MD") %>% 
  glm(resolution ~ victim_age + victim_race + victim_sex, 
      data = .,
      family = binomial())  
  
result_Baltimore <- 
  model_Baltimore %>% 
  broom::tidy() %>% 
  mutate(
    odd_ratio = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(term, odd_ratio , starts_with("CI")) %>% 
  knitr::kable(digits = 3)

```


### Logistic regression on all cities:

```{r model for all cities}
result_all <-
  homicide_clean %>% 
  nest(glm_data = -city_state) %>% 
  mutate(model = map(.x =glm_data, ~glm(resolution ~ victim_age + victim_race + victim_sex, 
                                   data =.x,
                                   family = binomial())),
         result = map(model,broom::tidy)) %>% 
  select(city_state, result) %>% 
  unnest(result) %>% 
  mutate(
    odd_ratio = exp(estimate),
    CI_lower = exp(estimate - 1.96 * std.error),
    CI_upper = exp(estimate + 1.96 * std.error)
  ) %>% 
  select(city_state, term, odd_ratio, starts_with("CI")) 
  
```

### Plots of odd ratio and CIs:

```{r Plots of odd ratio and CIs}
result_all %>% 
  filter(term == "victim_sexMale") %>% 
  mutate(city_state = fct_reorder(city_state, odd_ratio )) %>% 
  ggplot(aes(x = city_state, y = odd_ratio)) + 
  geom_point() + 
  geom_errorbar(aes(ymin = CI_lower, ymax = CI_upper)) + 
  theme(axis.text.x = element_text(angle = 90, hjust = 1))
```



## Quesiton 2:

### Import and tidy the data

```{r Q2-Import and tidy the data}
#Read and clean the data:
child_df <-
  read_csv("./data/birthweight.csv") %>% 
  mutate(babysex = as.factor(babysex),
         frace = as.factor(frace),
         mrace = as.factor(mrace),
         malform = as.factor(malform))

#Check and initial explore of the dataset
skimr::skim(child_df) 

#Check the levels of factors:
unique(pull(child_df, babysex))
unique(pull(child_df, frace))
unique(pull(child_df, mrace))
unique(pull(child_df, malform))
```

We can see that, there are no missing data in the dataset. From the glance of the data, focus on the continuous variable, we can see that all the data entry in the variable `pnumlbw` (previous number of low birth weight babies) and  `pnumsga` (number of prior small for gestational age babies) are zero, so we can drop these two variables. For some variable that is highly skewed, like `parity` (number of live births prior to this pregnancy) and `smoken` (average number of cigarettes smoked per day during pregnancy), it may not be appropriate to include the main model or should be treated as factors.

For discreet variables, we checked the level of them. Also, the variable `malform` is highly skewed and may not be appropriate to included in the meta analysis. 

### Model building: 


As the description above, we would like to use all the remaining variables. Also, some transformation need to be done. Then, we apply an AIC framework to select the most important variables. Also, as mothers race and fathers race are highly correlated, fathers race was droped in the model. 

```{r Select relevant variables}
child_df_modeldata <-
  child_df %>% 
  select(-pnumlbw,-pnumsga,-parity,-smoken,-malform, -frace) %>%
  mutate(momage = log(momage),
         ppbmi = log(ppbmi),
         ppwt = log(ppwt),
         delwt = log(delwt)) 

child_model_1 <-  lm(bwt~., data = child_df_modeldata)
```

```{r AIC, results="hide"}
child_model_2 <- step(child_model_1, direction = "backward")
```

```{r summary model}
summary(child_model_2)
child_newmodel <- lm(bwt ~  babysex + bhead + blength + 
                       fincome + gaweeks + mrace + 
                       log(ppbmi) + log(ppwt) + wtgain,
                     data=child_df)
```

So, our final model will be: 

$bwt = \beta_0+\beta_1babysex+\beta_2bhead+\beta_3blength+\beta_4fincome+\beta_5gaweeks+\beta_6mrace + \beta_7\log(ppbmi)+\beta_8wtgain$

```{r Plot}
child_df %>% 
  add_residuals(child_newmodel) %>% 
  add_predictions(child_newmodel) %>% 
  ggplot(aes(x = pred, y = resid)) +
  geom_point(alpha = 0.3) +
  stat_smooth(method = "lm")
```



### Cross Validation: 

```{r Cross Validaation:}
cv_df =
  crossv_mc(child_df,100) %>% 
  mutate(
    new_model = map(.x = train, ~lm(bwt ~  babysex + bhead + blength + 
                                      fincome + gaweeks + mrace + 
                                      log(ppbmi) + log(ppwt) + wtgain,
                                    data = .x)),
    old_model_1 = map(.x = train, ~lm(bwt~ gaweeks + blength, data = .x)),
    old_model_2 = map(.x = train, ~lm(bwt~ bhead * blength * babysex, data = .x))
  ) %>% 
  mutate(
    rmse_new = map2_dbl(.x = new_model, .y = test, ~rmse(model = .x, data = .y)),
    rmse_old_1 = map2_dbl(.x = old_model_1, .y = test, ~rmse(model = .x, data = .y)),
    rmse_old_2 = map2_dbl(.x = old_model_2, .y = test, ~rmse(model = .x, data = .y))
  ) 
  
cv_df %>% 
  select(starts_with("rmse")) %>% 
  pivot_longer(
    everything(),
    names_to = "model",
    values_to = "rmse",
    names_prefix = "rmse_"
  ) %>% 
  ggplot(aes(x = model, y = rmse)) +
  geom_violin()

```



## Question 3:

### Get the dataaset:

```{r get the dataset}
# I stroed the data in this repository:

#weather_df =
#  rnoaa::meteo_pull_monitors(
#  c("USW00094728"),
#  var = c("PRCP", "TMIN", "TMAX"),
#  date_min = "2017-01-01",
#  date_max = "2017-12-31") %>%
#  mutate(
#  name = recode(id, USW00094728 = "CentralPark_NY"),
#  tmin = tmin / 10,
#  tmax = tmax / 10) %>%
#  select(name, id, everything())
#weather_df %>% 
#  write_csv("./data/weather.csv")

weather_df <- read_csv("./data/weather.csv")
```

### Boostraping

```{r}
bootstraping_df <-
  weather_df %>%
  select(tmax, tmin) %>% 
  bootstrap(5000, id = "sample_id") %>% 
  mutate(model = map(.x = strap, ~lm(tmax~. ,data = .x)),
         result = map(model, broom::tidy),
         rsquare = map(model, broom::glance)) %>% 
  select(sample_id, result, rsquare) %>% 
  unnest(result, rsquare) 

bootstraping_result <-
  bootstraping_df %>% 
  select(sample_id, term, estimate, r.squared)
```


### Distribution of estimated r-sqarue:

```{r}
bootstraping_result %>% 
  select(sample_id, r.squared) %>% 
  distinct(sample_id, .keep_all = T) %>% 
  ggplot(aes(x = r.squared)) +
  geom_density()
```

### Distribution of log term:

```{r}
bootstraping_result %>% 
  select(sample_id, term, estimate) %>% 
  mutate(term = str_replace(term, "\\(Intercept\\)", "intercept")) %>% 
  pivot_wider(names_from = term,
              values_from = estimate) %>% 
  mutate(logterm = log(intercept * tmin)) %>% 
  ggplot(aes(x = logterm)) +
  geom_density()
```


